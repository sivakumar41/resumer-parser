{"classes":["EMAIL","ADDRESS","ACHIEVEMENTS","GRADUATION","PROJECTS","JOB ROLE","SKILLS","WORK EXPERIENCE","TECHNOLOGIES","CERTIFICATIONS","EXTRA CURRICULAR","ONLINE PPROFILES","PERCENTAGE","NAME"],"annotations":[["Ram.\r\n\r\nCell :  510-556-3630\r\n                                              \r\nProfessional Summary:\r\n\r\n\r\n10 years of total IT experience in all phases of Software Development Life Cycle including Analysis, Design, Implementation, integration, Testing, and Maintenance.\r\n8 years of experience in developing web, enterprise and SOA applications using Core Java, OOAD, Multi-Threading, JavaBeans, JSP, Servlets, JNDI, JDBC, Hibernate, JPA, Spring, WebServices(SOAP, Restful and Micro-Service), XSD, XML, XSLT, JSON, JAX-B, Apache Commons, EJB, JMS, MQ-Series, HTML, Ajax, Oracle and Linux/UNIX.\r\n2 years of experience in Big Data and Cloud based technologies like HDFS, SPARK, Kafka, Flume, Sqoop and AWS.\r\nExtensive experience on developing web applications using Spring Boot, Spring Core, Spring MVC, Spring ORM, Spring JPA,Spring Rest and Spring Cloud(PCF).\r\nExpertise in implementing persistence layer using JPA and Hibernate.\r\nExpertise working with SOAP, Rest and Microservices using CXF, Jersey and CloudFoundary.\r\nImplemented Microservices using Spring Core, Spring Boot, Spring Data, Spring Rest and Spring Cloud(PCF).\r\nExperience in Collections, Multi threading, Concurrency and memory management. \r\nExtensive experience in working with servers like WebLogic, WebSphere, JBOSS and Tomcat.\r\nExpertise in using XML Parsers SAX and DOM.\r\nGood experience in data structures and algorithms.\r\nGood experience in Junit and Mockito.\r\nImplemented  AWS(EC2, RDS, SNS, SQS, S3) to move customer care application in to Cloud environment.\r\nGood Experience in using Maven and ANT for building projects and Log4j for logging and debugging purposes.\r\nEffectiveness in coordinating with business team to fix defects and resolve issues.\r\nExperience in writing SQL queries, Stored Procedures for accessing and managing databases such as Oracle, DB2, MySQL.\r\nExperience with Tools: RAD, Eclipse, My Eclipse, Jenkins, Ant, Maven, Mercurial, Sonar, GIT, SVN, CVS, Perforce, Toad, SQLDeveloper, Code-Collaborator, SOAP-UI, RestClient-UI and Postman(chrome).\r\nExperience in Agile and waterfall modals.\r\nPracticing Agile  development frameworks Jira, Rally, VersionOne and standards, Test Driven Design & Development.\r\nPossess excellent communication, interpersonal, analytical and problem solving skills.\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\nTechnical Skills:\r\nJ2EE Technologies\t            : JDBC, JavaBeans, JSP, Servlets, EJB, JNDI, JMS. \r\nLanguages\t\t            : JAVA, Groovy, Python.\r\nWeb Technologies \t            : HTML, DHTML, JavaScript, JSON, AJAX.\r\nXML Technologies\t            : XML, DTD, XSLT, XSD, Xpath, JAXB SAX, DOM.\r\nDatabases\t\t            : Oracle 10g, 9i, MySQL, DB2 and Cassandra.\r\nOperating Systems\t            : UNIX, Linux, Windows 98/2000/NT/XP.\r\nApplication Servers\t     \t: WebSphere, Weblogic and JBoss.\r\nMiddleware\t\t     \t: Apache CAMEL, Oracle ESB, JMS and MQ-Series.\r\nIDE’s\t\t\t     \t: Eclipse, RAD and JDeveloper, TOAD, SQL Developer.\r\nFrameworks\t\t     \t: Apache CAMEL, Spring and Hadoop/ Big Data.\r\nORM Technologies \t     \t: Hibernate and JPA.\r\nWebservice Specifications\t: JAX-WS , JAX-RS and AXWAY APIGateway.\r\nUI Technologies\t        \t: JSP, JavaScript, JQuery, AJAX, CSS and HTML.\r\nVersion Control \t       \t: GIT, SVN, CVS and Perforce\r\nCloud Technologies \t\t: Cloud Foundry and AWS.                                                 \r\nTools\t                                \t: Ready API, Version One, JIRA, Parasoft, \r\n                                                  RestClient-UI and Postman(Chrome) and SOAP UI.\r\n Platform\t: 41st parameter(device  identification) and\r\n                                                  Fircosoft(to filter transactions and customers).\r\n\r\nEducation:                               Master of Computer Applications(MCA),  INDIA.  \r\n\r\nProfessional Experience:\r\n\r\nVerizon, TX.\r\nDec’16 – Tilldate.\r\nRole : Java Developer.\r\n\r\nDescription :  Verizon DVS Migration(CPF, Reconciliation, Cassandra Loader) consist of 800+ APIs currently running on the IBM Main Frame system. Intented of this program is to rewrite all the API in Java 1.8, Cassandra 3.0. Currently Verizon pays IBM based on the no., of MIPS the API gets max in the day. Re-write API in Java with will reduce the cost spent for the IBM and the API scalability will be greatly increased with Cassandra. \r\n\r\nResponsibility: \r\n\r\nImplemented Microservice’s(Read API’s, Write API’s) using cloudfoundary.\r\nUsed Netflix OSS stack to provide infrastructure for micro-services(config server, eureka server, zuul proxy, ribbon and hystrix).\r\nCreated shell scripts on Linux for enabling seed data loading into Cassandra tables.\r\nCreated application for data modelling to allow various DB2 to Cassandra table migration use cases.   \r\nEnabled code generation DDL files, Control Files, Spark Configuration files, Spring Boot Artifacts.\r\nDeveloped spark scripts by using Scala shell as per requirements. \r\nWorked with spark core, Spark Streaming and spark SQL modules of Spark \r\nDeveloped multiple POCs using Spark and deployed on the Yarn cluster, compared the performance of Spark, with Hive and SQL/Teradata. \r\nDeveloped Kafka producer and consumers, Cassandra clients and Spark along with components on HDFS, Hive. \r\nInvolved in converting Hive/SQL queries into Spark transformations using Spark RDDs, Python and Scala.\r\nCreated application to create control files for performing seed data migration from DB2 to Cassandra called init load. Data files are created by Mainframe system. Various formats of data files are Fixed Width and delimited.\r\nCreated CPFTestSuite Automation tool for measuring CPF functionality, essential for detecting any configuration issues in preload tables.\r\nCreated ReconLogAnalyzer tool that will perform log analysis for missing and mismatch log statements and produce the output in an excel file.\r\nCreated application to create control files for performing seed data migration from DB2 to Cassandra called init load. Data files are created by Mainframe system. Various formats of data files are Fixed Width and delimited.\r\nCreated Jenkins builds for few custom applications.\r\nImplemented Test cases using Junit and Tested web services with REST Client.\r\nProactively monitor database systems ensuring availability and performance.\r\n\r\nEnvironment: Java/J2EE, Spring Core, Spring Boot, Spring JPA, Spring Rest, Spring Security, Spring Cloud, JPA, Microservices(PCF), Spark, HDFS(Hadoop), Kafka, Jenkins, AWS, GIT, Maven, MQ-Series, Mainframe, RAD, Junit  DB2, Cassandra and Oracle.\r\n\r\nGoogle Inc, Mountain View.\r\nMarch’16 – Dec’16.\r\nRole : Java Developer.\r\n\r\nDescription: Cyber-insurance is a predictive risk analytics tool implemented to analyse businesses and individual users Internet-based risks(Security Breach, Data Breach, Malware, Phishing, Spam, hacking and cloud service down) including the company’s industry, geography, scale, services and security posture.\r\n\r\nResponsibility: \r\nInvolved in the requirement gathering, design and development of Catastrophe modeling.\r\nUsed Netflix OSS stack to provide infrastructure for micro-services(config server, eureka server, zuul proxy, ribbon and hystrix).\r\nExtensively used different Spring modules like Spring Boot, Spring Core, Spring JPA  Spring Rest and Spring Cloud.  \r\nImplemented cost calculator engines for AAL(Average Annual Loss), SD(Standard Deviation) and CV(Coefficient of Variation).\r\nUsed Spring Rest to implement controller layer.\r\nUsed JPA to implement Service and Repository layers.\r\nImplemented Micro-service’s using Pivotal Cloud Foundry(Spring Cloud).  \r\nUsed Groovy script for test automation. \r\nUsed Swagger to Document API’s. \r\nInvolved in converting Hive/SQL queries into Spark transformations using Spark RDDs, Python and Scala. \r\nDeveloped the code for Importing and exporting data into HDFS and Hive using Sqoop. \r\nResponsible for writing Hive Queries for analyzing data in Hive warehouse using HQL. \r\nWrote complex Hive queries and UDFs in Java and Python \r\nInvolved in defining job flows using Oozie for scheduling jobs to manage apache Hadoop jobs by directed.\r\nDeveloping Hive User Defined Functions in java, compiling them into jars and adding them to the HDFS and executing them with Hive Queries.\r\nDesigned and deployed isolated Search DCs for Datastax Solr Clusters. \r\nDeveloped Solr indexes and queries to span over multiple DCs. \r\nInvolved in writing API Testing,Junit testing, enhancements, bug fixing.\r\n\r\nEnvironment: Core Java(java 8), J2EE, JPA, Spring Core,Spring MVC, Spring JPA, Spring Rest, Spring Security, Spring Cloud, HDFS, HIVE, SPARK, Apache SOLR, Kafka, Zookeeper, XML, Groovy, JSON, JavaScript, AngularJS, Swagger, Jenkins,  Junit, Tomcat, Postman(Chrome), Git, MYSQL and UNIX/Linux.\r\n\r\n\r\nWells Fargo,  San Leandro, CA.                                                          \r\nMay’15  – March’2016.\r\nRole: Java Developer.\r\nDescription:  New Device Fingerprinting is one of the core application in Gen 3 FP&A (Fraud Prevention & Authentication ) for building a more intelligent and efficient fraud mitigation, authentication and alerting strategies  for online  and cross channel authentication use cases.\r\n\r\nResponsibility: \r\nInvolved in the requirement gathering and architecture design and development of New Device Fingerprint project.\r\nReengineering existing platform to a Microservices based architecture.\r\nReengineered platform to support 100% virtualization.\r\ninvolved in  development using 41st Parameter, Core Java - J2ee, Multi-threading, Groovy,  Spring, Hibernate, Apache CAMEL, Web services(SOAP and Rest), Maven, Oracle and Weblogic.\r\ninstalled an updated version of 41st Parameter (external vendor) code to do Device fingerprinting.\r\nImplemented different features related to Device fingerprinting in  AuthC Service .\r\nUsed Apache Camel for creating routes using Web service.\r\nUsed spring boot to bootstrap the basic configuration of the project. \r\nDeveloped Data access layer using ORM framework hibernate for mapping database scheme to Object model.\r\nExtensively used different Spring modules like Spring Boot, Spring Core, Spring MVC, Spring DAO and Spring JMS. \r\nUsed Ready API Tool to Implement functional and integation tests.\r\nPerformed Unit testing using JUNIT and Mockito.\r\nUsed Splunk tool in order to analyze the logs in the applications.\r\nExtensively used Groovy for functional tests.\r\nUsed Cassandra CQL with Java API's to retrieve data from Cassandra tables.\r\nInvolved in writing different DDL and DML scripts for functional tests.\r\nManaged code for different releases by branching and merging using SVN.\r\nUsed CI tools like Jenkins.\r\nUsed JIRA as a change request , defect tracking and project status tracking system in the project.\r\n\r\nEnvironment: 41st Parameter, Core Java, Groovy, J2EE, Hibernate, Spring,Spring Boot, EJB, Apache CAMEL, WebServices(SOAP, Restful and Amazon), XML, JSON,  Ready API, Log4j, Weblogic, ActiveMQ, SQL Developer,MQ-Series, Jenkins, Splunk, Junit, Mockito, Docker, Oracle DB, Cassandra, Putty and UNIX/Linux.\r\n\r\n\r\nBank of America, Agoura Hills,CA.                                                                         \r\nMar 14  – Apr 15 .\r\nRole: Java Developer.\r\nDescription:  This project will be used by the RMD Department of BOFA. RMD will issue loans to the borrowers based on collateral Status before issuing the loan RMD checks that whether that collateral is insured or not and collateral’s Social Security Number through third party agencies and finally RMD checks whether borrowers is paying tax properly for that collateral or not with the help of third party agency.\r\n\r\n\r\nResponsibility: \r\nUsed Agile methodology for design and development of project.\r\nImplemented User Interface using JSP, HTML, CSS, Ajax, JavaScript and AngularJS.\r\nImplemented Tax  and  Loan ID modules using Spring Framework.\r\nImplemented Persistence layer using Hibernate JPA.\r\nCreated and maintained the configuration of the Spring Application Framework (IOC) and implemented business logic using EJB.\r\nImplemented SOAP Services(JAX-WS) to interact with external systems like Fidelity.\r\nConverted  Business to customer services into Restful Services.\r\nHave good experience on continuous integration tool Jenkins.\r\nImplemented some fuzzy logic’s using Hadoop MapReduce Programming.\r\nImplemented  AWS Redshift (a petabyte-scale data warehouse service in the cloud).\r\nConverted EJB MDB’s in to Spring MDP’s using Spring JMS Module and moved into Amazon cloud(AWS).\r\nHandled all the service nodes and components on Amazon cloud, including handling Amazon service outages.\r\nImplemented NO-SQL DB(Cassandra) to store poisoned messages.\r\nCQL is used to query Cassandra data from dev center.\r\nPerformed importing data from various sources to the Cassandra cluster using Java/Python APIs or Sqoop. \r\nResponsible for bug fixes and documentation.\r\nUsed Linux OS for Development and Production Environment.\r\nAbility to learn and adapt quickly to the emerging new technologies.\r\n\r\nEnvironment: Core Java, J2EE, JSP, Servlets, Hadoop/Big Data, Splunk Spring Core, Spring MVC, Spring Data, Hibernate-JPA, EJB, WebServices(SOAP, Restful and Amazon WebService), Kafka, Apache CAMEL, AngularJS, Ajax, XML,  JavaScript, JSON, CSS, HTML, Log4j, SONOR,Weblogic, Putty, UNIX/Linux, SQL, SQL Developer, Jenkins, Sqoop, Cassandra DB, MySQL and Oracle DB.\r\n\r\n\r\nBank of America, Jersey City, NJ.                   \t   \t\t                                 \r\nMay’13 – March’14.\r\nTitle:  Enterprise Transaction Scanning in AML (Anti Money Laundering).\r\nRole:  Java Developer.\r\nDescription: Anti Money Laundering(AML) is the policy in Bank of America where Bank of America does not want to be  used  in the  process to conceal the true source of funds that were originally derived from criminal activity or in the process of funding criminal activity, including terrorism.\r\nAML Policy Statement is intended to guard against Bank of America’s unintentional involvement in criminal activity, and to reinforce Bank of America’s policy of cooperation with law enforcement and regulatory agencies.\r\nUnder the Project AML, Bank of America will,\r\nTake reasonable steps to determine the true identity of all customers and beneficial ownership of Bank of America products and services .\r\nReport all identified instances of suspicious activity to the extent that it can do so under all applicable foreign and domestic laws .\r\nAvoid providing support or assistance to customers seeking to deceive law enforcement agencies through the provision of false, altered, incomplete or missing information or by informing customers that their activities are, may be, or have been investigated or reported as suspicious.\r\nAML uses the tool called Fircosoft for scanning the Enterprise transactions and report the suspicious activities through the system called ‘ETS (Enterprise Transaction Scanning)’. ETS will scan all the wired transactions against the watch list (central repository of suspicious individuals, countries and cities) stored in ETS database. \r\n\r\nResponsibilites:\r\nInteraction with Business users on daily basis for gathering the Requirements.\r\nInvolving in the preparing low level design.\r\nInvolved in the development of Report Generation module. Which includes volume statistics report, Sanctions Monitoring Metrics report, TPS report.\r\nImplemented Spring MVC, dependency Injection (DI) features along with Hibernate \r\nImplemented  Online List Management (OLM)  and  FMM module  using Spring and Hibernate.\r\nCreated Configuration files for the application using Spring framework.\r\nImplemented a RESTful interface for the search and Address services\r\nImplemented SOAP Services(JAX-WS) to interact with external systems.\r\nWrote various SQL, PL/SQL queries and stored procedures for data retrieval.\r\nPerformed Unit testing using JUNIT and Mockito.\r\nUsed Linux OS for Development and Production Environment, Wrote UNIX Shell scripts and used UNIX environment to deploy the EAR and read the logs.\r\n\r\nEnvironment: Core Java, multithreading, Fircosoft, J2EE, JSP, Servlets, Spring Core, Spring MVC, Spring ORM, Spring Batch, Hibernate, JPA, WebServices(SOAP and Restful), AnjularJS, Ajax, XML,  JavaScript, JSON, CSS , HTML, SVN, Jenkins, Log4j, Weblogic, Putty, UNIX/Linux, SQL, SQL Developer, Mockito, Cassandra, Junit, Mockito and Oracle DB.\r\n\r\n\r\n\r\nFidelity Investments, Atlanta, GA.      \t\t                              \r\nFeb’12 – April’13.\r\nTitle: TradeClearing System.\r\nRole: Java Developer\r\n\r\nTradeClear had following functionalities:\r\nCentralized clearing: Listed Derivatives are traded on numerous exchanges and booked into a large number of front office booking systems within the firm. TradeClear consolidates information flow from substantially all relevant booking systems and most major clearing houses where Client has membership rights. \r\nReal-time Processing: Listed derivative transactions must be balanced and cleared on the same day they are traded. This gives a little as 90 minutes to identify mismatches in bookings and correctly clear the day’s business. \r\n \r\nResponsibility:\r\nResponsible for gathering business requirements, review the requirements and converting them to detailed design documents and clarification documents.\r\nDeveloped UI and backend applications using Struts, Spring, Hibernate, Java, EJB 3.0, JSP, HTML, DHTML, JavaScript and AJAX.\r\nImplemented JSP, Struts Tag Libraries, Java Script and CSS for developing User for creating/generating Hibernate classes and configuration XML’s and to also manage CRUD operations (insert, update, and delete).\r\nImplemented a RESTful interface for the Front-end response.\r\nUsed Web Services to get price from external Business Entities.\r\nDeveloped reusable services using BPEL to transfer data between heterogeneous systems\r\nUsing different Adapters.\r\nImplemented messaging using TIBCO EMS.\r\nImplemented integration between the BPEL worklist and Oracle eBusiness Suite .\r\nImplemented security for BPEL services using OWSM. \r\nResponsible for integration of different modules. \r\nCreated JUnit test cases, and Development of JUnit classes.\r\nConfigured log4j to enable/disable logging in application.\r\nInvolved in Code Reviews of other modules, documents, test cases.\r\nWrote UNIX Shell scripts and used UNIX environment to deploy the application.\r\nResponsible in coordination with offshore team, attending daily and weekly scrum meetings to update the work status, issues clarifications etc.\r\n\r\nEnvironment: Core Java,J2EE, JDeveloper, Spring, Hibernate, SOA 10g(BPEL), Weblogic Server, Webservices(SOAP and Restful), JMS, PL/SQL, Sql Developer, XML HTML, JavaScript, SVN, Maven, Log4j, JUnit, Sybase , JBoss, Oracle, DB2, SAP, Mainframe(COBOL), MQ-Series,MySQL, Windows XP, RAD and Unix. \r\n\r\n\r\nPrudential,   Newark, NJ.      \t          \t           \t                                 \r\nMay’10 – Dec’11\r\nRole: Java Developer.    \r\nProject: 4Front is an application provides a single point of access for teleconsultants for legacy \r\nsystems (E.g.: CAPSIL, SALAS, OPAL and OB).  It allows users in Customer Services and other areas of the business to Verify the identification of a caller, Maintain a history of a caller’s contact, Make with enquiries, Perform alterations to a customer’s policy, Investigate the New Business, Review the Direct Debit instructions, Produce outputs (fax, letter, etc.), Provide valuations, Pass the call to another 4Front user and Automate the call hand-off.\r\n\r\nResponsibility:      \r\nDay to day support activities. \r\nMeeting the Client SLA on the production tickets.\r\nDesign and development of new change requests using  Java, struts, JSP and EJB.\r\nImplemented integration between the BPEL worklist and Oracle eBusiness Suite.\r\nResponsible for all the SDLC phases of a change request including testing and live support.\r\n\r\nEnvironment: Core Java , J2ee, Oracle Fusion(BPEL), JSP, Eclipse, Servlet, XML, Struts, Tiles, AJAX, EJB, JUnit, JBoss, websphere Application Server , Ant, JavaScript, CSS, Log4J, Junit,HTML, PL/SQL, CVS, MQ-Series, Mainframe(COBOL), RAD and  DB2. \r\n\r\nHilmar Cheese, India.\t\t                                                     \r\nSep’ 08 – Feb’ 2010\r\nTitle:  Custom Business Application.\r\nRole: Java Developer.\r\nDescription: This project has been designed and developed to process online order request. This project consist of different module such as online User Registration, Update User Information, Submit order online, payment, process order and delivery of order.\r\n\r\nResponsibility:\r\nInvolved in gathering requirements, Analysis, Design, Development and testing of the entire Application.\r\nInvolved in all phases of SDLC (Software Development Life Cycle).\r\nCreated UML diagrams like class diagrams and activity diagrams using the Rational Rose.\r\nParticipated in the design and development of application using JSP, HTML, CSS and JavaScript.\r\nUsed Eclipse as IDE tool to develop the application and JIRA for bug and issue tracking.\r\nDesigned and Developed the presentation layer using AJAX for RUI(Rich User Interface).\r\nJSON is used in conjunction with JavaScript for making HTTP requests.\r\nJQuery is used for validation.\r\nDeveloped the presentation tier of the application using Struts framework and MVC design pattern.\r\nConfigured the Hibernate ORM framework as persistence layer for the backend by using hibernate.confg.xml \r\nDesigned and developed DAO’s for accessing the POJO’s and updating the DB tables using the POJO’s, Java Collections, and Synchronization etc.\r\nUsed Hibernate object relation mappings (ORM) for the database operations on MySQL.\r\nDeveloped and modified the stored procedures, the DAO (Data Access Objects) and VO (value Object) classes for separating the Data Access logic and business logic.\r\nExtensively participated in application integration. Spring is used to integrate Struts and Hibernate. Implemented interceptors for Spring and Hibernate.\r\nTransactions were implemented using declarative transactions in Spring with transaction managers capable of supporting Hibernate.\r\nConfiguration issues in the various frameworks used were identified and resolved to extract an acceptable level of performance in terms of efficiency, response and robustness.\r\nConsumed Web Services as a gateway for the payment through the third-party.\r\nDeveloped Web Services using SOA, SOAP, WSDL, UDDI and JAX-WS,JAX-RPC programming models.\r\nUsed Ant as build tool for building and deploying it into Weblogic Server. Ant scripts are used for automating build process.\r\nDeveloped and execute unit tests and test suites for product components using JUnit Testing Used.\r\n\r\nEnvironment: Core Java, J2EE1.6.x, JDK, JSP, Struts 2.x, Tiles, JMS, Spring 3.x, Hibernate 3.0, MySQL, Eclipse, WebSphere Application Server, JBOSS, JSON, AJAX, JQuery, Web Services(SOAP,WSDL),Ant, JavaScript, CSS, Log4J, Junit,HTML, PL/SQL, CVS, MySQL and DB2.\r\n\r\n\r\nR-Systems International Ltd, India.\t\t    \t                       \r\nOct’07 - July’08\r\nTitle: RMS (Repayment Management System).\r\nRole: Software Programmer.\r\nDescription: RMS is Repayment Management System. Case appears in RMS only after the final disbursement of loan amount. In case of partial disbursement; only after the last disbursement the case will appear in RMS. RMS deals with how does the customer repays the Loan i.e. through his salary deduction or online transfer from checking a/c, etc.\r\n\r\nResponsibility: \r\nInvolved in Development of RMS Enhancements like RMS Transaction, RMS Monthly History, Scheme Change maker/checker, Customer service query, Non Provisioning Assets screens like specific provision manual marking, writeoff manual marking, sale of asset, property value updating, collateral value updating and ground rent prospect entry.\r\nDeveloped sub-modules of non provisioning Assets like sale of asset, writeoff manual marking and ground rent prospect entry.\r\nInvolved in requirements planning, analysis and design discussions with the technical team.\r\nDocumentation & review of requirements with design team.\r\nInvolved in preparing program specifications and testing scripts and updating the same.\r\nDeveloped stored procedures, Functions, views and also wrote PL/SQL scripts.\r\nUsed JSF layout for view of MVC.\r\nResponsible in troubleshooting application and understanding the same.\r\nUsed web services to fetch data synchronously from the other interfaces\r\nIntegrated Spring DAO for data access using with Hibernate.\r\nCoordinated with team in troubleshooting and fixing production application issues.\r\nInvolved in setting up processes, procedures, knowledge transfer to offshore teams.\r\n\r\nEnvironment: Core Java, J2EE, XSL, XML, JSP, Struts, Tiles, Spring 2.x, Hibernate, JavaScript, HTML, CSS, Oracle, Websphere Application Server, DB2, Web Services (WSDL, SOAP), SQL/PL SQL and windows. \r\n\r\n",{"entities":[[0,4,"NAME"],[354,358,"SKILLS"],[360,364,"SKILLS"],[366,381,"SKILLS"],[383,392,"SKILLS"],[394,397,"SKILLS"],[399,407,"SKILLS"],[409,413,"SKILLS"],[415,419,"SKILLS"],[421,430,"SKILLS"],[432,435,"SKILLS"],[437,443,"SKILLS"],[445,456,"SKILLS"],[491,494,"SKILLS"],[496,499,"SKILLS"],[501,505,"SKILLS"],[507,511,"SKILLS"],[513,518,"SKILLS"],[520,534,"SKILLS"],[536,539,"SKILLS"],[541,544,"SKILLS"],[546,555,"SKILLS"],[557,561,"SKILLS"],[2563,2566,"SKILLS"],[2568,2571,"SKILLS"],[2573,2577,"SKILLS"],[2579,2582,"SKILLS"],[2584,2589,"SKILLS"],[2591,2599,"SKILLS"],[2663,2673,"SKILLS"],[3141,3144,"SKILLS"],[3146,3156,"SKILLS"],[3158,3164,"SKILLS"],[3166,3170,"SKILLS"],[3172,3175,"SKILLS"],[3180,3185,"SKILLS"],[3214,3217,"SKILLS"],[3219,3222,"SKILLS"],[3224,3227,"SKILLS"],[3283,3287,"SKILLS"],[3403,3407,"SKILLS"],[3409,3417,"SKILLS"],[3718,3754,"GRADUATION"],[3757,3763,"ADDRESS"],[3838,3853,"JOB ROLE"],[24537,24541,"SKILLS"],[24543,24546,"SKILLS"],[24548,24551,"SKILLS"],[24553,24556,"SKILLS"],[24558,24564,"SKILLS"],[24566,24571,"SKILLS"],[24573,24583,"SKILLS"],[24585,24594,"SKILLS"],[24596,24606,"SKILLS"],[24608,24612,"SKILLS"],[24612,24613,"SKILLS"],[24614,24617,"SKILLS"],[24619,24625,"SKILLS"],[24657,24660,"SKILLS"],[24662,24674,"SKILLS"],[24689,24695,"SKILLS"],[24696,24699,"SKILLS"]]}]]}